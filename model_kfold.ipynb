{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:18:03.229367Z",
     "iopub.status.busy": "2025-06-20T20:18:03.229073Z",
     "iopub.status.idle": "2025-06-20T20:18:05.580310Z",
     "shell.execute_reply": "2025-06-20T20:18:05.579405Z",
     "shell.execute_reply.started": "2025-06-20T20:18:03.229348Z"
    },
    "id": "b745627a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "\tprecision_score,\n",
    "\trecall_score,\n",
    "\tf1_score,\n",
    "\tconfusion_matrix,\n",
    "\troc_curve,\n",
    "\tauc,\n",
    "\tclassification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:18:05.909867Z",
     "iopub.status.busy": "2025-06-20T20:18:05.909382Z",
     "iopub.status.idle": "2025-06-20T20:18:05.915585Z",
     "shell.execute_reply": "2025-06-20T20:18:05.914666Z",
     "shell.execute_reply.started": "2025-06-20T20:18:05.909842Z"
    },
    "id": "55225588",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def carregar_dados_csv(file):\n",
    "\n",
    "\ttry:\n",
    "\n",
    "\t\tdf_completo = pd.read_csv(file)\n",
    "\n",
    "\t\treturn df_completo\n",
    "\n",
    "\texcept FileNotFoundError:\n",
    "\n",
    "\t\tprint(f\"Erro: O arquivo '{file}' não foi encontrado.\")\n",
    "\t\tprint(\"Rode o ZeaMays para gerar o arquivo CSV.\")\n",
    "\t\treturn None\n",
    "\n",
    "\texcept KeyError as e:\n",
    "\n",
    "\t\tprint(f\"Erro: Uma ou mais colunas não encontradas no arquivo: {e}\")\n",
    "\t\treturn None\n",
    "\n",
    "\texcept Exception as e:\n",
    "\n",
    "\t\tprint(f\"Ocorreu um erro inesperado: {e}\")\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:18:07.685555Z",
     "iopub.status.busy": "2025-06-20T20:18:07.685251Z",
     "iopub.status.idle": "2025-06-20T20:20:20.750209Z",
     "shell.execute_reply": "2025-06-20T20:20:20.749281Z",
     "shell.execute_reply.started": "2025-06-20T20:18:07.685534Z"
    },
    "id": "iv-c6pxUDzWk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metricas = \"df_metricas_seq.csv\"\n",
    "# metricas = \"/kaggle/input/zea-mays-1-0/df_metricas_seq.csv\"\n",
    "\n",
    "df_metricas = carregar_dados_csv(metricas)\n",
    "\n",
    "if df_metricas is not None:\n",
    "\tprint(\"\\nHead do DataFrame:\")\n",
    "\tprint(df_metricas.shape)\n",
    "\tprint(df_metricas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:20:20.751997Z",
     "iopub.status.busy": "2025-06-20T20:20:20.751679Z",
     "iopub.status.idle": "2025-06-20T20:20:21.686167Z",
     "shell.execute_reply": "2025-06-20T20:20:21.685281Z",
     "shell.execute_reply.started": "2025-06-20T20:20:20.751977Z"
    },
    "id": "8181d3c6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "remover_colunas = [\"Chr\", \"SourceAnnotation\", \"Start\", \"End\", \"Score\", \"Strand\", \"Phase\", \"Attributes\", \"label\"]\n",
    "\n",
    "df_modificado = df_metricas.drop(columns=remover_colunas)\n",
    "\n",
    "print(\"\\nDataFrame após remover colunas:\")\n",
    "print(df_modificado.shape)\n",
    "print(df_modificado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:20:21.687413Z",
     "iopub.status.busy": "2025-06-20T20:20:21.687120Z",
     "iopub.status.idle": "2025-06-20T20:20:21.691733Z",
     "shell.execute_reply": "2025-06-20T20:20:21.690831Z",
     "shell.execute_reply.started": "2025-06-20T20:20:21.687386Z"
    },
    "id": "9719e56e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "coluna_alvo = 'COS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:20:21.693929Z",
     "iopub.status.busy": "2025-06-20T20:20:21.693674Z",
     "iopub.status.idle": "2025-06-20T20:20:21.731401Z",
     "shell.execute_reply": "2025-06-20T20:20:21.730590Z",
     "shell.execute_reply.started": "2025-06-20T20:20:21.693909Z"
    },
    "id": "1bb2d556",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def verfica_unique (df, coluna):\n",
    "\t\n",
    "\tif coluna in df.columns:\n",
    "\n",
    "\t\tcontagem_valores = df[coluna].value_counts()\n",
    "\n",
    "\t\tprint(f\"Contagem de cada valor único na coluna '{coluna}':\")\n",
    "\t\tprint(contagem_valores)\n",
    "\n",
    "\t\tvalores_unicos = df[coluna].unique()\n",
    "\t\tprint(f\"\\nValores únicos na coluna '{coluna}':\")\n",
    "\t\tprint(valores_unicos)\n",
    "\n",
    "\t\tnumero_de_valores_unicos = df[coluna].nunique()\n",
    "\t\tprint(f\"\\nA coluna '{coluna}' possui {numero_de_valores_unicos} valores únicos distintos.\")\n",
    "\n",
    "\telse:\n",
    "\t\tprint(f\"A coluna '{coluna}' não foi encontrada no DataFrame.\")\n",
    "\t\tprint(\"Colunas disponíveis:\", df.columns.tolist())\n",
    "\n",
    "verfica_unique(df_modificado, coluna_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:20:21.733108Z",
     "iopub.status.busy": "2025-06-20T20:20:21.732652Z",
     "iopub.status.idle": "2025-06-20T20:20:21.779012Z",
     "shell.execute_reply": "2025-06-20T20:20:21.777903Z",
     "shell.execute_reply.started": "2025-06-20T20:20:21.733075Z"
    },
    "id": "8887cf4e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extrair_elemento_transponivel(texto):\n",
    "  \n",
    "\ttry:\n",
    "\t\treturn texto.split('/')[1]\n",
    "\texcept IndexError:\n",
    "\t\treturn\n",
    "\t\n",
    "df_modificado[coluna_alvo] = df_modificado[coluna_alvo].apply(extrair_elemento_transponivel)\n",
    "\n",
    "verfica_unique(df_modificado, coluna_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:20:21.780121Z",
     "iopub.status.busy": "2025-06-20T20:20:21.779790Z",
     "iopub.status.idle": "2025-06-20T20:20:22.960378Z",
     "shell.execute_reply": "2025-06-20T20:20:22.959324Z",
     "shell.execute_reply.started": "2025-06-20T20:20:21.780095Z"
    },
    "id": "e8bae107",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ocorrencia = 1\n",
    "\n",
    "contagens = df_modificado[coluna_alvo].value_counts()\n",
    "\n",
    "valores_para_manter = contagens[contagens > ocorrencia].index\n",
    "\n",
    "df_filtrado = df_modificado[df_modificado[coluna_alvo].isin(valores_para_manter)]\n",
    "\n",
    "verfica_unique(df_filtrado, coluna_alvo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:32:24.145800Z",
     "iopub.status.busy": "2025-06-20T20:32:24.145368Z",
     "iopub.status.idle": "2025-06-20T20:32:24.229442Z",
     "shell.execute_reply": "2025-06-20T20:32:24.228059Z",
     "shell.execute_reply.started": "2025-06-20T20:32:24.145764Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T20:21:55.700266Z",
     "iopub.status.busy": "2025-06-20T20:21:55.698842Z",
     "iopub.status.idle": "2025-06-20T20:21:56.681950Z",
     "shell.execute_reply": "2025-06-20T20:21:56.681067Z",
     "shell.execute_reply.started": "2025-06-20T20:21:55.700226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Encontra todas as colunas que começam com o prefixo \"chaos_\"\n",
    "colunas_para_remover = [col for col in df_filtrado.columns if col.startswith('ZMays/Agrup\\chaos_')]\n",
    "\n",
    "# Cria um novo DataFrame sem essas colunas\n",
    "df_filtrado = df_filtrado.drop(columns=colunas_para_remover)\n",
    "\n",
    "print(\"Colunas removidas:\", colunas_para_remover)\n",
    "print(\"\\nNovo formato do DataFrame:\", df_filtrado.shape)\n",
    "print(\"Primeiras linhas do DataFrame limpo:\")\n",
    "print(df_filtrado.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtrado.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-20T20:32:07.372Z",
     "iopub.execute_input": "2025-06-20T20:31:54.049689Z",
     "iopub.status.busy": "2025-06-20T20:31:54.049310Z"
    },
    "id": "WeDpXMDe1vLw",
    "outputId": "c750cb96-bcb8-44e7-cc25-67f12be13ca1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "nome_coluna_alvo = 'COS'\n",
    "\n",
    "df_modelo = df_filtrado.copy()\n",
    "\n",
    "# Amostragem de 10% do DataFrame filtrado para um pseudo-treinamento\n",
    "# df_modelo = df_filtrado.sample(frac=0.01, random_state=42)\n",
    "\n",
    "if nome_coluna_alvo not in df_modelo.columns:\n",
    "\n",
    "\tprint(f\"ERRO: Coluna alvo '{nome_coluna_alvo}' não encontrada no DataFrame!\")\n",
    "\n",
    "else:\n",
    "  df_modelo.dropna(inplace=True)\n",
    "  y_original = df_modelo[nome_coluna_alvo]\n",
    "  X_original = df_modelo.drop(columns=[nome_coluna_alvo])\n",
    "\n",
    "  print(f\"\\nVariável Alvo Selecionada: '{nome_coluna_alvo}' (Multiclasse)\")\n",
    "  print(\"-\" * 50)\n",
    "\n",
    "  # Codificar Features Categóricas em X (One-Hot Encoding)\n",
    "  colunas_categoricas_X = X_original.select_dtypes(include=['object', 'category']).columns\n",
    "  X_codificado = pd.get_dummies(X_original, columns=colunas_categoricas_X, drop_first=True)\n",
    "  feature_names = X_codificado.columns.tolist()\n",
    "\n",
    "  print(\"\\nFeatures (X) após One-Hot Encoding (primeiras linhas):\")\n",
    "  print(X_codificado.head())\n",
    "  print(f\"Número de features após encoding: {X_codificado.shape[1]}\")\n",
    "  print(\"-\" * 50)\n",
    "\n",
    "  # Codificar Variável Alvo (y) para formato numérico 0..N-1\n",
    "  le = LabelEncoder()\n",
    "  y_codificada = le.fit_transform(y_original) # Converte strings/categorias para 0, 1, 2...\n",
    "\n",
    "  print(f\"\\nCodificação da Variável Alvo '{nome_coluna_alvo}':\")\n",
    "  print(\"Classes originais:\", le.classes_)\n",
    "  print(\"Classes codificadas (únicas):\", np.unique(y_codificada))\n",
    "  print(\"Alvo (y) após codificação (primeiras ocorrências):\", y_codificada[:5])\n",
    "  print(\"-\" * 50)\n",
    "\n",
    "  print(df_modelo.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMcTbFtduEUB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def kfold_classification(model, X, y, n_splits=5, average='weighted'):\n",
    "\tkf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\t# Converta y para array numpy se for Series/DataFrame\n",
    "\ty = np.array(y) if not isinstance(y, np.ndarray) else y\n",
    "\n",
    "\t# Métricas de classificação\n",
    "\tf1_scores, precision_scores, recall_scores, confusion_matrices = [], [], [], []\n",
    "\n",
    "\tfor fold, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
    "\t\t# Para matrizes esparsas, usamos índices diretamente\n",
    "\t\tX_train, X_test = X[train_idx], X[test_idx]\n",
    "\t\ty_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "\t\t# Treino com barra de progresso\n",
    "\t\twith tqdm(total=100, desc=f\"Fold {fold+1}/{n_splits}\", leave=False) as pbar:\n",
    "\t\t\tmodel.fit(X_train, y_train)\n",
    "\t\t\tfor _ in range(100):\n",
    "\t\t\t\tpbar.update(1)\n",
    "\n",
    "\t\t# Predição\n",
    "\t\ty_pred = model.predict(X_test)\n",
    "\n",
    "\t\t# Cálculo de métricas\n",
    "\t\tf1 = f1_score(y_test, y_pred, average=average)\n",
    "\t\tprecision = precision_score(y_test, y_pred, average=average)\n",
    "\t\trecall = recall_score(y_test, y_pred, average=average)\n",
    "\n",
    "\t\tf1_scores.append(f1)\n",
    "\t\tprecision_scores.append(precision)\n",
    "\t\trecall_scores.append(recall)\n",
    "\n",
    "\t\t# Armazena relatórios completos\n",
    "\t\tconfusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "\t\tfpr, tpr = [], []\n",
    "\t\t#y_pred_proba = model.predict_proba(X_test) # Probabilidades para a curva ROC\n",
    "\t\tfor i, class_label in enumerate(model.classes_):\n",
    "\t\t\tfpr_i, tpr_i, _ = roc_curve(y_test == class_label, y_pred == class_label)\n",
    "\t\t\tfpr.append(fpr_i)\n",
    "\t\t\ttpr.append(tpr_i)\n",
    "\n",
    "\t# Retorno dos resultados\n",
    "\treturn {\n",
    "\t\t'f1': {\n",
    "\t\t\t'mean': np.mean(f1_scores),\n",
    "\t\t\t'std': np.std(f1_scores),\n",
    "\t\t\t'all': f1_scores\n",
    "\t\t},\n",
    "\t\t'precision': {\n",
    "\t\t\t'mean': np.mean(precision_scores),\n",
    "\t\t\t'std': np.std(precision_scores),\n",
    "\t\t\t'all': precision_scores\n",
    "\t\t},\n",
    "\t\t'recall': {\n",
    "\t\t\t'mean': np.mean(recall_scores),\n",
    "\t\t\t'std': np.std(recall_scores),\n",
    "\t\t\t'all': recall_scores\n",
    "\t\t},\n",
    "\t\t'confusion_matrices': confusion_matrices,\n",
    "\t\t'fpr': fpr,\n",
    "\t\t'tpr': tpr,\n",
    "\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAmkjZPBze2Z",
    "outputId": "64e03a89-2e06-4c23-f32e-9028fd42337c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# k_values = [3,5,7,10]\n",
    "# modelNames = ['XGBoost', 'RF', 'GBT', 'SVM']\n",
    "\n",
    "# params_rf = {'n_estimators': 100, 'random_state': 42, 'min_samples_split': 2, 'min_samples_leaf':1}\n",
    "# params_rf.update(n_estimators=120, class_weight='balanced')\n",
    "# rf_model = RandomForestClassifier(**params_rf)\n",
    "\n",
    "# params_xgb = {\n",
    "# \t'n_estimators': 100,\n",
    "# \t'random_state': 42,\n",
    "# \t'use_label_encoder': False,\n",
    "# \t'eval_metric': 'logloss'\n",
    "# }\n",
    "# params_xgb['objective'] = 'multi:softprob'\n",
    "# params_xgb['eval_metric'] = 'mlogloss'\n",
    "# params_xgb.update(n_estimators=120, learning_rate=0.1, max_depth=4)\n",
    "# xgb_model = XGBClassifier(n_estimators=120, learning_rate=0.1, max_depth=4)\n",
    "\n",
    "# gbt_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "# svm_model = SVC(kernel='linear', C=1.0, random_state=42, probability=True)\n",
    "\n",
    "# models = [xgb_model, rf_model, gbt_model, svm_model]\n",
    "# results = []\n",
    "\n",
    "# output_dir = '/kaggle/working/models'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "\n",
    "# print(\"Iniciando avaliação de K-Fold e salvamento de modelos\\n\")\n",
    "# for i in range(len(models)):\n",
    "# \tresult = {\n",
    "# \t\t'model_name': modelNames[i],\n",
    "# \t\t'f1': {},\n",
    "# \t\t'precision': {},\n",
    "# \t\t'recall': {},\n",
    "# \t\t'confusion_matrices': {},\n",
    "# \t\t'fpr': {},\n",
    "# \t\t'tpr': {}\n",
    "# \t}\n",
    "\n",
    "# \tX_input = X_codificado.values if hasattr(X_codificado, 'values') else X_codificado\n",
    "# \ty_input = y_codificada.values if hasattr(y_codificada, 'values') else y_codificada\n",
    "\n",
    "# \tif modelNames[i] == 'SVM':\n",
    "# \t\tscaler = StandardScaler()\n",
    "# \t\tX_input = scaler.fit_transform(X_input)\n",
    "\n",
    "# \tfor k in k_values:\n",
    "# \t\tprint(f\"\\n Model = {modelNames[i]} --- K = {k}\")\n",
    "# \t\tmetrics = kfold_classification(models[i], X_input, y_input, n_splits=k)\n",
    "\n",
    "# \t\tresult['f1'][k] = {'mean': metrics['f1']['mean'], 'std': metrics['f1']['std'], 'all': metrics['f1']['all']}\n",
    "# \t\tresult['precision'][k] = {'mean': metrics['precision']['mean'], 'std': metrics['precision']['std'], 'all': metrics['precision']['all']}\n",
    "# \t\tresult['recall'][k] = {'mean': metrics['recall']['mean'], 'std': metrics['recall']['std'], 'all': metrics['recall']['all']}\n",
    "# \t\tresult['confusion_matrices'][k] = metrics['confusion_matrices']\n",
    "# \t\tresult['fpr'][k], result['tpr'][k] = metrics['fpr'], metrics['tpr']\n",
    "\n",
    "# \tresults.append(result)\n",
    "\n",
    "# \tprint(f\"\\n----------------------------------------------------\")\n",
    "# \tprint(f\"Treinando e salvando modelo final para: {modelNames[i]}...\")\n",
    "\n",
    "# \tfinal_model_to_save = models[i]\n",
    "# \tfinal_model_to_save.fit(X_input, y_input)\n",
    "\n",
    "# \tfile_path = os.path.join(output_dir, f'modelo_{modelNames[i].lower()}_final.joblib')\n",
    "# \tjoblib.dump(final_model_to_save, file_path)\n",
    "# \tprint(f\"Modelo final salvo em: {file_path}\")\n",
    "\n",
    "# \tif modelNames[i] == 'SVM':\n",
    "# \t\tscaler_path = os.path.join(output_dir, 'scaler_svm.joblib')\n",
    "# \t\tjoblib.dump(scaler, scaler_path)\n",
    "# \t\tprint(f\"Scaler do SVM salvo em: {scaler_path}\")\n",
    "\n",
    "# \tresults_path = os.path.join(output_dir, 'evaluation_results.joblib')\n",
    "# \tjoblib.dump(results, results_path)\n",
    "# \tprint(f\"Resultados de avaliação intermediários salvos em: {results_path}\")\n",
    "# \tprint(f\"----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:27:20.335825Z",
     "iopub.status.busy": "2025-06-20T18:27:20.335474Z",
     "iopub.status.idle": "2025-06-20T18:27:20.351630Z",
     "shell.execute_reply": "2025-06-20T18:27:20.350605Z",
     "shell.execute_reply.started": "2025-06-20T18:27:20.335790Z"
    },
    "id": "ee9eb21d",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_single_model_results(display_name, model_results, model_object, k_values, feature_names):\n",
    "    \"\"\"\n",
    "    Plota os resultados da validação k-fold para um único modelo.\n",
    "\n",
    "    Args:\n",
    "        display_name (str): O nome 'bonito' do modelo para usar nos títulos.\n",
    "        model_results (dict): Dicionário contendo os resultados (f1, precision, etc.) para o modelo.\n",
    "        model_object (object): O objeto do modelo treinado (carregado do joblib).\n",
    "        k_values (list): A lista de valores de K usados (ex: [3, 5, 7, 10]).\n",
    "        feature_names (list): Lista com os nomes das colunas/features.\n",
    "    \"\"\"\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A']\n",
    "    metrics = ['f1', 'precision', 'recall']\n",
    "    metric_names = ['F1-Score', 'Precision', 'Recall']\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    fig.suptitle(f'Desempenho do Modelo: {display_name}\\n', fontsize=16, fontweight='bold')\n",
    "    gs = fig.add_gridspec(2, 3, height_ratios=[3, 1])\n",
    "    ax_main = fig.add_subplot(gs[0, :])\n",
    "\n",
    "    for j, metric in enumerate(metrics):\n",
    "        x = k_values\n",
    "        y = [model_results[metric][k]['mean'] for k in x]\n",
    "        y_err = [model_results[metric][k]['std'] for k in x]\n",
    "        ax_main.errorbar(x, y, yerr=y_err, fmt='-o', color=colors[j],\n",
    "                       ecolor=colors[j]+'AA', capsize=5, linewidth=2.5,\n",
    "                       markersize=8, label=metric_names[j])\n",
    "        for k, val in zip(x, y):\n",
    "            ax_main.text(k, val + 0.01, f'{val:.3f}', ha='center', va='bottom',\n",
    "                       fontsize=9, color=colors[j])\n",
    "\n",
    "    ax_main.set_title('Métricas por Número de Folds', pad=20, fontsize=14)\n",
    "    ax_main.set_xlabel('Número de Folds (K)', labelpad=10, fontsize=12)\n",
    "    ax_main.set_ylabel('Valor da Métrica', labelpad=10, fontsize=12)\n",
    "    ax_main.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3, fontsize=12)\n",
    "    ax_main.grid(True, alpha=0.3)\n",
    "    ax_main.set_ylim(0, 1.05)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nMATRIZES DE CONFUSÃO\")\n",
    "    for k in k_values:\n",
    "        fig_conf, axes = plt.subplots(1, 1, figsize=(8, 4))\n",
    "        fig_conf.suptitle(f'{display_name} - Matriz de Confusão do Teste (K={k})', y=1.05)\n",
    "        cm = model_results['confusion_matrices'][k][-1]\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_object.classes_)\n",
    "        disp.plot(ax=axes, cmap='Blues', values_format='d', colorbar=True)\n",
    "        axes.set_title(f'Fold {k}')\n",
    "        axes.set_xlabel('Valores preditos')\n",
    "        axes.set_ylabel('Valores reais')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"\\n Resumo Estatístico - {display_name}\")\n",
    "    print(f\"{'K':<5} {'F1-Score':<10} {'Precision':<10} {'Recall':<10}\")\n",
    "    print(\"-\" * 40)\n",
    "    for k in k_values:\n",
    "        print(f\"{k:<5}\", end=\" \")\n",
    "        for metric in metrics:\n",
    "            val = model_results[metric][k]['mean']\n",
    "            print(f\"{val:.4f}\".ljust(10), end=\" \")\n",
    "        print()\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\n\")\n",
    "\n",
    "    if hasattr(model_object, 'feature_importances_'):\n",
    "        importances = model_object.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        num_features_to_plot = min(len(feature_names), 20)\n",
    "        plt.figure(figsize=(12, max(6, num_features_to_plot * 0.3)))\n",
    "        plt.title(f\"Importância das Features - {display_name} (Top {num_features_to_plot})\")\n",
    "        sns.barplot(x=importances[indices][:num_features_to_plot],\n",
    "                    y=[feature_names[i] for i in indices[:num_features_to_plot]])\n",
    "        plt.xlabel(\"Importância Relativa\")\n",
    "        plt.ylabel(\"Feature\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    print(f\"--- Avaliação de {display_name} Concluída ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-20T18:27:23.628121Z",
     "iopub.status.busy": "2025-06-20T18:27:23.627828Z",
     "iopub.status.idle": "2025-06-20T18:27:27.397327Z",
     "shell.execute_reply": "2025-06-20T18:27:27.396423Z",
     "shell.execute_reply.started": "2025-06-20T18:27:23.628101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "models_to_analyze = [\n",
    "    {\n",
    "        \"display_name\": \"Random Forest - K-Fold\",\n",
    "        \"internal_name\": \"RF\",\n",
    "        \"model_object_path\": \"models/kfold_models/modelo_rf_kfold.joblib\"\n",
    "    },\n",
    "    {\n",
    "        \"display_name\": \"GBoost - K-Fold\",\n",
    "        \"internal_name\": \"GBT\",\n",
    "        \"model_object_path\": \"models/kfold_models/modelo_gbt_kfold.joblib\"\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "results_file_path = \"models/kfold_models/evaluation_results.joblib\"\n",
    "k_values = [3, 5]\n",
    "\n",
    "try:\n",
    "    \n",
    "    all_results = joblib.load(results_file_path)\n",
    "    results_dict = {res['model_name']: res for res in all_results}\n",
    "    print(f\"Arquivo de resultados '{results_file_path}' carregado com sucesso.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    \n",
    "    results_dict = None\n",
    "    print(f\"ERRO: Arquivo de resultados '{results_file_path}' não encontrado. Verifique o caminho.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    \n",
    "    results_dict = None\n",
    "    print(f\"Ocorreu um erro inesperado ao carregar os resultados: {e}\")\n",
    "\n",
    "if results_dict:\n",
    "    \n",
    "    print(\"\\n--- INICIANDO GERAÇÃO DE GRÁFICOS ---\")\n",
    "    \n",
    "    for model_info in models_to_analyze:\n",
    "        display_name = model_info['display_name']\n",
    "        internal_name = model_info['internal_name']\n",
    "        model_path = model_info['model_object_path']\n",
    "\n",
    "        print(f\"\\n{'='*20} ANÁLISE DO MODELO: {display_name.upper()} {'='*20}\")\n",
    "\n",
    "        if internal_name not in results_dict:\n",
    "            print(f\"AVISO: Resultados para '{internal_name}' não encontrados no arquivo de avaliação. Pulando este modelo.\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            model_object = joblib.load(model_path)\n",
    "            print(f\"Objeto do modelo carregado de: {model_path}\")\n",
    "\n",
    "            current_results = results_dict[internal_name]\n",
    "\n",
    "            # Chama a função de plotagem\n",
    "            # A variável 'feature_names' deve existir da célula de pré-processamento!\n",
    "            plot_single_model_results(\n",
    "                display_name=display_name,\n",
    "                model_results=current_results,\n",
    "                model_object=model_object,\n",
    "                k_values=k_values,\n",
    "                feature_names=feature_names\n",
    "            )\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            \n",
    "            print(f\"ERRO: Arquivo do modelo não encontrado em '{model_path}'. Verifique o caminho. Pulando este modelo.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"ERRO ao processar o modelo '{display_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7699103,
     "sourceId": 12220447,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7706439,
     "sourceId": 12231006,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 246559748,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
