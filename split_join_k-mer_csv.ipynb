{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab76d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "def dividir_csv_em_n_partes(arquivo_original: str, pasta_saida: str, n_partes: int) -> Optional[List[str]]:\n",
    "    \"\"\"\n",
    "    Divide um arquivo CSV em N partes aproximadamente iguais.\n",
    "\n",
    "    Args:\n",
    "        arquivo_original (str): O caminho para o arquivo CSV a ser dividido.\n",
    "        pasta_saida (str): O diretório onde as partes divididas serão salvas.\n",
    "        n_partes (int): O número de partes para dividir o arquivo.\n",
    "\n",
    "    Returns:\n",
    "        Optional[List[str]]: Uma lista contendo os caminhos para os arquivos CSV criados, ou None em caso de erro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Lendo o arquivo original: '{arquivo_original}'...\")\n",
    "        df = pd.read_csv(arquivo_original)\n",
    "        print(f\"Dimensões do DataFrame original ('{os.path.basename(arquivo_original)}'): {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # Garante que a pasta de saída exista\n",
    "        os.makedirs(pasta_saida, exist_ok=True)\n",
    "\n",
    "        # Usa numpy.array_split para dividir o dataframe em N pedaços de forma eficiente.\n",
    "        # Esta função lida com casos onde o número de linhas não é perfeitamente divisível por n_partes.\n",
    "        dfs_divididos = np.array_split(df, n_partes)\n",
    "\n",
    "        caminhos_arquivos_saida = []\n",
    "        # Usa o nome do arquivo original como base para os nomes das partes\n",
    "        nome_base = os.path.splitext(os.path.basename(arquivo_original))[0]\n",
    "\n",
    "        print(f\"Dividindo em {n_partes} partes na pasta '{pasta_saida}'...\")\n",
    "        for i, df_parte in enumerate(dfs_divididos):\n",
    "            arquivo_saida = os.path.join(pasta_saida, f\"{nome_base}_parte_{i+1}_de_{n_partes}.csv\")\n",
    "            print(f\"Salvando Parte {i+1}: '{os.path.basename(arquivo_saida)}' ({len(df_parte)} linhas)\")\n",
    "            df_parte.to_csv(arquivo_saida, index=False)\n",
    "            caminhos_arquivos_saida.append(arquivo_saida)\n",
    "\n",
    "        print(f\"\\nArquivo '{arquivo_original}' dividido com sucesso!\")\n",
    "        return caminhos_arquivos_saida\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: O arquivo '{arquivo_original}' não foi encontrado.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao dividir o arquivo: {e}\")\n",
    "        return None\n",
    "\n",
    "def compactar_lista_csv(lista_arquivos_csv: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Compacta uma lista de arquivos CSV em arquivos ZIP individuais.\n",
    "\n",
    "    Args:\n",
    "        lista_arquivos_csv (List[str]): A lista de caminhos dos arquivos CSV para compactar.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Uma lista dos caminhos dos arquivos ZIP criados.\n",
    "    \"\"\"\n",
    "    caminhos_zip_criados = []\n",
    "    print(\"\\n--- Etapa: Compactando os CSVs divididos ---\")\n",
    "    for arquivo_csv in lista_arquivos_csv:\n",
    "        try:\n",
    "            if not os.path.exists(arquivo_csv):\n",
    "                print(f\"Aviso: Arquivo de entrada '{arquivo_csv}' não encontrado. O ZIP não será criado.\")\n",
    "                continue\n",
    "\n",
    "            # Define o nome do arquivo ZIP de saída na mesma pasta do CSV\n",
    "            nome_base = os.path.splitext(arquivo_csv)[0]\n",
    "            arquivo_zip_saida = f\"{nome_base}.zip\"\n",
    "\n",
    "            with zipfile.ZipFile(arquivo_zip_saida, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                zipf.write(arquivo_csv, os.path.basename(arquivo_csv))\n",
    "            print(f\"Arquivo '{os.path.basename(arquivo_csv)}' compactado em '{os.path.basename(arquivo_zip_saida)}'\")\n",
    "            caminhos_zip_criados.append(arquivo_zip_saida)\n",
    "        except Exception as e:\n",
    "            print(f\"Ocorreu um erro ao compactar o arquivo '{arquivo_csv}': {e}\")\n",
    "    return caminhos_zip_criados\n",
    "\n",
    "def juntar_n_csvs_em_dataframe(lista_arquivos_csv: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Junta múltiplos arquivos CSV em um único DataFrame do pandas.\n",
    "\n",
    "    Args:\n",
    "        lista_arquivos_csv (List[str]): Uma lista de caminhos para os arquivos CSV a serem juntados.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: O DataFrame concatenado ou None se ocorrer um erro.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataframes = []\n",
    "        print(\"\\n--- Etapa: Juntando os CSVs em um DataFrame ---\")\n",
    "        for arquivo_csv in lista_arquivos_csv:\n",
    "            print(f\"Lendo o arquivo '{os.path.basename(arquivo_csv)}'...\")\n",
    "            df_parte = pd.read_csv(arquivo_csv)\n",
    "            print(f\"  > Dimensões: {df_parte.shape[0]} linhas, {df_parte.shape[1]} colunas\")\n",
    "            dataframes.append(df_parte)\n",
    "\n",
    "        if not dataframes:\n",
    "            print(\"Nenhum DataFrame para concatenar.\")\n",
    "            return None\n",
    "\n",
    "        df_concatenado = pd.concat(dataframes, ignore_index=True)\n",
    "        print(\"\\nArquivos CSV juntados em um DataFrame com sucesso!\")\n",
    "        print(f\"Dimensões do DataFrame final concatenado: {df_concatenado.shape[0]} linhas, {df_concatenado.shape[1]} colunas\")\n",
    "        return df_concatenado\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro de arquivo não encontrado: {e}. Verifique se todos os arquivos na lista existem.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ocorreu um erro ao juntar os arquivos CSV: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6768b16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Etapa 1: Dividindo o CSV ---\n",
      "Lendo o arquivo original: 'ZMays/Agrup/k-mer/k-mer_agrupado.csv'...\n",
      "Dimensões do DataFrame original ('k-mer_agrupado.csv'): 98987 linhas, 5462 colunas\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vinícius\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividindo em 5 partes na pasta 'ZMays/Agrup/k-mer/divididos'...\n",
      "Salvando Parte 1: 'k-mer_agrupado_parte_1_de_5.csv' (19798 linhas)\n",
      "Salvando Parte 2: 'k-mer_agrupado_parte_2_de_5.csv' (19798 linhas)\n",
      "Salvando Parte 3: 'k-mer_agrupado_parte_3_de_5.csv' (19797 linhas)\n",
      "Salvando Parte 4: 'k-mer_agrupado_parte_4_de_5.csv' (19797 linhas)\n",
      "Salvando Parte 5: 'k-mer_agrupado_parte_5_de_5.csv' (19797 linhas)\n",
      "\n",
      "Arquivo 'ZMays/Agrup/k-mer/k-mer_agrupado.csv' dividido com sucesso!\n",
      "\n",
      "--- Etapa: Compactando os CSVs divididos ---\n",
      "Arquivo 'k-mer_agrupado_parte_1_de_5.csv' compactado em 'k-mer_agrupado_parte_1_de_5.zip'\n",
      "Arquivo 'k-mer_agrupado_parte_2_de_5.csv' compactado em 'k-mer_agrupado_parte_2_de_5.zip'\n",
      "Arquivo 'k-mer_agrupado_parte_3_de_5.csv' compactado em 'k-mer_agrupado_parte_3_de_5.zip'\n",
      "Arquivo 'k-mer_agrupado_parte_4_de_5.csv' compactado em 'k-mer_agrupado_parte_4_de_5.zip'\n",
      "Arquivo 'k-mer_agrupado_parte_5_de_5.csv' compactado em 'k-mer_agrupado_parte_5_de_5.zip'\n",
      "Arquivos ZIP criados: 5 de 5\n",
      "\n",
      "--- Etapa: Juntando os CSVs em um DataFrame ---\n",
      "Lendo o arquivo 'k-mer_agrupado_parte_1_de_5.csv'...\n",
      "  > Dimensões: 19798 linhas, 5462 colunas\n",
      "Lendo o arquivo 'k-mer_agrupado_parte_2_de_5.csv'...\n",
      "  > Dimensões: 19798 linhas, 5462 colunas\n",
      "Lendo o arquivo 'k-mer_agrupado_parte_3_de_5.csv'...\n",
      "  > Dimensões: 19797 linhas, 5462 colunas\n",
      "Lendo o arquivo 'k-mer_agrupado_parte_4_de_5.csv'...\n",
      "  > Dimensões: 19797 linhas, 5462 colunas\n",
      "Lendo o arquivo 'k-mer_agrupado_parte_5_de_5.csv'...\n",
      "  > Dimensões: 19797 linhas, 5462 colunas\n",
      "\n",
      "Arquivos CSV juntados em um DataFrame com sucesso!\n",
      "Dimensões do DataFrame final concatenado: 98987 linhas, 5462 colunas\n",
      "\n",
      "--- Etapa 4: Verificação e Pré-visualização ---\n",
      "\n",
      "Pré-visualização do DataFrame final (primeiras 5 linhas):\n",
      "                 nameseq         A         C         G         T        AA  \\\n",
      "0    5_13437450_13437571  0.327869  0.213115  0.180328  0.278689  0.107438   \n",
      "1  2_140681423_140703276  0.274000  0.232360  0.231994  0.261645  0.082963   \n",
      "2  4_233416075_233416397  0.328173  0.204334  0.263158  0.204334  0.093168   \n",
      "3    3_51304584_51304870  0.365854  0.146341  0.132404  0.355401  0.171329   \n",
      "4    9_10968395_10968475  0.209877  0.308642  0.358025  0.123457  0.050000   \n",
      "\n",
      "         AC        AG        AT        CA  ...    TTTTCT    TTTTGA    TTTTGC  \\\n",
      "0  0.057851  0.066116  0.099174  0.107438  ...  0.008547  0.000000  0.000000   \n",
      "1  0.056011  0.067268  0.067771  0.067817  ...  0.000595  0.000870  0.000595   \n",
      "2  0.086957  0.074534  0.071429  0.096273  ...  0.000000  0.000000  0.003145   \n",
      "3  0.048951  0.052448  0.094406  0.045455  ...  0.000000  0.003546  0.003546   \n",
      "4  0.050000  0.062500  0.050000  0.100000  ...  0.000000  0.000000  0.000000   \n",
      "\n",
      "     TTTTGG    TTTTGT    TTTTTA    TTTTTC    TTTTTG    TTTTTT  label  \n",
      "0  0.000000  0.000000  0.000000  0.008547  0.000000  0.008547  6-mer  \n",
      "1  0.000549  0.000641  0.000595  0.000641  0.000458  0.000366  6-mer  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  6-mer  \n",
      "3  0.000000  0.003546  0.000000  0.000000  0.003546  0.000000  6-mer  \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  6-mer  \n",
      "\n",
      "[5 rows x 5462 columns]\n",
      "\n",
      "Pré-visualização do DataFrame final (últimas 5 linhas):\n",
      "                     nameseq         A         C         G         T  \\\n",
      "98982  4_239643403_239643447  0.288889  0.311111  0.222222  0.177778   \n",
      "98983    3_54350144_54354221  0.315596  0.220942  0.204022  0.259441   \n",
      "98984    2_20203678_20204129  0.267699  0.232301  0.234513  0.265487   \n",
      "98985  4_199999392_199999605  0.271028  0.271028  0.257009  0.200935   \n",
      "98986  6_121108364_121125364  0.282866  0.216223  0.217164  0.283748   \n",
      "\n",
      "             AA        AC        AG        AT        CA  ...    TTTTCT  \\\n",
      "98982  0.113636  0.090909  0.068182  0.022727  0.136364  ...  0.000000   \n",
      "98983  0.106206  0.051754  0.077999  0.079470  0.086338  ...  0.001473   \n",
      "98984  0.070953  0.039911  0.055432  0.099778  0.070953  ...  0.000000   \n",
      "98985  0.070423  0.065728  0.079812  0.051643  0.065728  ...  0.000000   \n",
      "98986  0.092412  0.050235  0.067765  0.072471  0.069235  ...  0.001412   \n",
      "\n",
      "         TTTTGA    TTTTGC   TTTTGG    TTTTGT    TTTTTA    TTTTTC    TTTTTG  \\\n",
      "98982  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "98983  0.000982  0.000737  0.00000  0.000246  0.000246  0.000737  0.000737   \n",
      "98984  0.000000  0.000000  0.00000  0.000000  0.000000  0.002237  0.000000   \n",
      "98985  0.000000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "98986  0.000765  0.000412  0.00053  0.000647  0.000471  0.001236  0.000941   \n",
      "\n",
      "         TTTTTT  label  \n",
      "98982  0.000000  6-mer  \n",
      "98983  0.000491  6-mer  \n",
      "98984  0.000000  6-mer  \n",
      "98985  0.000000  6-mer  \n",
      "98986  0.000647  6-mer  \n",
      "\n",
      "[5 rows x 5462 columns]\n",
      "\n",
      "Dimensões totais verificadas do DataFrame final: (98987, 5462)\n",
      "\n",
      "Verificando integridade com o arquivo original...\n",
      "\n",
      "SUCESSO: DataFrame final é idêntico ao DataFrame original!\n"
     ]
    }
   ],
   "source": [
    "# --- PARÂMETROS DE EXECUÇÃO ---\n",
    "# Defina em quantas partes você quer dividir o CSV\n",
    "N_PARTES = 5\n",
    "\n",
    "# Caminhos dos arquivos e pastas\n",
    "arquivo_csv_original = 'ZMays/Agrup/k-mer/k-mer_agrupado.csv'\n",
    "pasta_saida_partes = 'ZMays/Agrup/k-mer/divididos' # Pasta para salvar as partes\n",
    "\n",
    "# --- ETAPA 1: Dividindo o CSV em N partes ---\n",
    "print(\"--- Etapa 1: Dividindo o CSV ---\")\n",
    "lista_de_partes_csv = dividir_csv_em_n_partes(\n",
    "    arquivo_original=arquivo_csv_original,\n",
    "    pasta_saida=pasta_saida_partes,\n",
    "    n_partes=N_PARTES\n",
    ")\n",
    "\n",
    "if lista_de_partes_csv:\n",
    "\n",
    "    lista_de_zips = compactar_lista_csv(lista_de_partes_csv)\n",
    "    print(f\"Arquivos ZIP criados: {len(lista_de_zips)} de {len(lista_de_partes_csv)}\")\n",
    "\n",
    "    dataframe_final = juntar_n_csvs_em_dataframe(lista_de_partes_csv)\n",
    "\n",
    "    # --- ETAPA 4: Verificação e Pré-visualização ---\n",
    "    if dataframe_final is not None:\n",
    "        print(\"\\n--- Etapa 4: Verificação e Pré-visualização ---\")\n",
    "        print(\"\\nPré-visualização do DataFrame final (primeiras 5 linhas):\")\n",
    "        print(dataframe_final.head())\n",
    "        print(\"\\nPré-visualização do DataFrame final (últimas 5 linhas):\")\n",
    "        print(dataframe_final.tail())\n",
    "        print(f\"\\nDimensões totais verificadas do DataFrame final: {dataframe_final.shape}\")\n",
    "\n",
    "        # Verificação de integridade comparando com o arquivo original\n",
    "        try:\n",
    "            \n",
    "            print(\"\\nVerificando integridade com o arquivo original...\")\n",
    "            df_original_releitura = pd.read_csv(arquivo_csv_original)\n",
    "            \n",
    "            if df_original_releitura.equals(dataframe_final):\n",
    "                print(\"\\nSUCESSO: DataFrame final é idêntico ao DataFrame original!\")\n",
    "                \n",
    "            else:\n",
    "                print(\"\\nFALHA: DataFrame final NÃO é idêntico ao DataFrame original. Algo deu errado.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\nErro ao tentar verificar com o original: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7612b0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 98987 entries, 0 to 98986\n",
      "Columns: 5462 entries, nameseq to label\n",
      "dtypes: float64(5460), object(2)\n",
      "memory usage: 4.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_final.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4081420d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     nameseq         A         C         G         T  \\\n",
      "0        5_13437450_13437571  0.327869  0.213115  0.180328  0.278689   \n",
      "1      2_140681423_140703276  0.274000  0.232360  0.231994  0.261645   \n",
      "2      4_233416075_233416397  0.328173  0.204334  0.263158  0.204334   \n",
      "3        3_51304584_51304870  0.365854  0.146341  0.132404  0.355401   \n",
      "4        9_10968395_10968475  0.209877  0.308642  0.358025  0.123457   \n",
      "...                      ...       ...       ...       ...       ...   \n",
      "98982  4_239643403_239643447  0.288889  0.311111  0.222222  0.177778   \n",
      "98983    3_54350144_54354221  0.315596  0.220942  0.204022  0.259441   \n",
      "98984    2_20203678_20204129  0.267699  0.232301  0.234513  0.265487   \n",
      "98985  4_199999392_199999605  0.271028  0.271028  0.257009  0.200935   \n",
      "98986  6_121108364_121125364  0.282866  0.216223  0.217164  0.283748   \n",
      "\n",
      "             AA        AC        AG        AT        CA  ...    TTTTCT  \\\n",
      "0      0.107438  0.057851  0.066116  0.099174  0.107438  ...  0.008547   \n",
      "1      0.082963  0.056011  0.067268  0.067771  0.067817  ...  0.000595   \n",
      "2      0.093168  0.086957  0.074534  0.071429  0.096273  ...  0.000000   \n",
      "3      0.171329  0.048951  0.052448  0.094406  0.045455  ...  0.000000   \n",
      "4      0.050000  0.050000  0.062500  0.050000  0.100000  ...  0.000000   \n",
      "...         ...       ...       ...       ...       ...  ...       ...   \n",
      "98982  0.113636  0.090909  0.068182  0.022727  0.136364  ...  0.000000   \n",
      "98983  0.106206  0.051754  0.077999  0.079470  0.086338  ...  0.001473   \n",
      "98984  0.070953  0.039911  0.055432  0.099778  0.070953  ...  0.000000   \n",
      "98985  0.070423  0.065728  0.079812  0.051643  0.065728  ...  0.000000   \n",
      "98986  0.092412  0.050235  0.067765  0.072471  0.069235  ...  0.001412   \n",
      "\n",
      "         TTTTGA    TTTTGC    TTTTGG    TTTTGT    TTTTTA    TTTTTC    TTTTTG  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000  0.000000  0.008547  0.000000   \n",
      "1      0.000870  0.000595  0.000549  0.000641  0.000595  0.000641  0.000458   \n",
      "2      0.000000  0.003145  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3      0.003546  0.003546  0.000000  0.003546  0.000000  0.000000  0.003546   \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "98982  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "98983  0.000982  0.000737  0.000000  0.000246  0.000246  0.000737  0.000737   \n",
      "98984  0.000000  0.000000  0.000000  0.000000  0.000000  0.002237  0.000000   \n",
      "98985  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "98986  0.000765  0.000412  0.000530  0.000647  0.000471  0.001236  0.000941   \n",
      "\n",
      "         TTTTTT  label  \n",
      "0      0.008547  6-mer  \n",
      "1      0.000366  6-mer  \n",
      "2      0.000000  6-mer  \n",
      "3      0.000000  6-mer  \n",
      "4      0.000000  6-mer  \n",
      "...         ...    ...  \n",
      "98982  0.000000  6-mer  \n",
      "98983  0.000491  6-mer  \n",
      "98984  0.000000  6-mer  \n",
      "98985  0.000000  6-mer  \n",
      "98986  0.000647  6-mer  \n",
      "\n",
      "[98987 rows x 5462 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframe_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
